{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65b0c596",
   "metadata": {},
   "source": [
    "# Q1: In this question you have to scrape data using the filters available on the webpage You have to use the location and \n",
    "salary filter.  \n",
    "You have to scrape data for ‚ÄúData Scientist‚Äù designation for first 10 job results.  \n",
    "You have to scrape the job-title, job-location, company name, experience required.  \n",
    "The location filter to be used is ‚ÄúDelhi/NCR‚Äù. The salary filter to be used is ‚Äú3-6‚Äù lakhs  \n",
    "The task will be done as shown in the below steps:  \n",
    "1. first get the web page https://www.naukri.com/ \n",
    "2. Enter ‚ÄúData Scientist‚Äù in ‚ÄúSkill, Designations, and Companies‚Äù field.  \n",
    "3. Then click the search button.  \n",
    "4. Then apply the location filter and salary filter by checking the respective boxes  \n",
    "5. Then scrape the data for the first 10 jobs results you get.  \n",
    "6. Finally create a dataframe of the scraped data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "aa388193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Experience_Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist: Artificial Intelligence</td>\n",
       "      <td>Gurugram</td>\n",
       "      <td>IBM</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurugram</td>\n",
       "      <td>Collegedunia</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Innovaccer</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...</td>\n",
       "      <td>Monnai</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Tiketcom</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Sociomix</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data scientist</td>\n",
       "      <td>Gurugram</td>\n",
       "      <td>Growthjockey</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...</td>\n",
       "      <td>Essenware</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist (Telco)</td>\n",
       "      <td>Gurugram, Bengaluru</td>\n",
       "      <td>PayU</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Times Internet</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Job Title  \\\n",
       "1   Data Scientist: Artificial Intelligence   \n",
       "2                            Data Scientist   \n",
       "3                            Data Scientist   \n",
       "4                            Data Scientist   \n",
       "5                            Data Scientist   \n",
       "6                            Data Scientist   \n",
       "7                            Data scientist   \n",
       "8                            Data Scientist   \n",
       "9                    Data Scientist (Telco)   \n",
       "10                           Data Scientist   \n",
       "\n",
       "                                             Location    Company_Name  \\\n",
       "1                                            Gurugram             IBM   \n",
       "2                                            Gurugram    Collegedunia   \n",
       "3                                               Noida      Innovaccer   \n",
       "4   Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...          Monnai   \n",
       "5                                               Noida        Tiketcom   \n",
       "6                                           New Delhi        Sociomix   \n",
       "7                                            Gurugram    Growthjockey   \n",
       "8   Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...       Essenware   \n",
       "9                                 Gurugram, Bengaluru            PayU   \n",
       "10                                              Noida  Times Internet   \n",
       "\n",
       "   Experience_Required  \n",
       "1              3-7 Yrs  \n",
       "2              0-2 Yrs  \n",
       "3              2-7 Yrs  \n",
       "4              3-7 Yrs  \n",
       "5              3-7 Yrs  \n",
       "6              0-5 Yrs  \n",
       "7              0-1 Yrs  \n",
       "8              2-5 Yrs  \n",
       "9              2-7 Yrs  \n",
       "10             3-8 Yrs  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import libraries\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd \n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#setup selenium webdriver\n",
    "driver=webdriver.Chrome()\n",
    "\n",
    "#open naukri.com\n",
    "driver.get('https://www.naukri.com/')\n",
    "\n",
    "# wait until page is fully loaded and input fields are present\n",
    "wait=WebDriverWait(driver,30)\n",
    "\n",
    "#locate the skill field and enter the skill field as Data Scientist using the send_keys method\n",
    "\n",
    "skill=driver.find_element(By.XPATH,'.//input[@placeholder=\"Enter skills / designations / companies\"]')\n",
    "skill.send_keys(\"Data Scientist\")\n",
    "\n",
    "#locate the search buttton\n",
    "search_button=wait.until(EC.element_to_be_clickable((By.XPATH,'.//div[@class=\"qsbSubmit\"]')))\n",
    "search_button.click()\n",
    "\n",
    "#Select checkbox of Delhi/Ncr(location filter)\n",
    "location_filter=wait.until(EC.element_to_be_clickable((By.XPATH,'.//label[@for=\"chk-Delhi / NCR-cityTypeGid-\"]/i[1]')))\n",
    "location_filter.click()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "#filter salary range from 3-6 lakh\n",
    "salary_filter=wait.until(EC.presence_of_element_located((By.XPATH,'.//label[@for=\"chk-3-6 Lakhs-ctcFilter-\"]/i[1]')))\n",
    "salary_filter.click()\n",
    "\n",
    "jobs=[]\n",
    "\n",
    "time.sleep(4)\n",
    "\n",
    "#locate all the required element which we wants to scrap like Job_title,location, experience,company_name\n",
    "job_element=wait.until(EC.presence_of_all_elements_located((By.XPATH,'.//div[@class=\"cust-job-tuple layout-wrapper lay-2 sjw__tuple \"]')))\n",
    "for element in job_element[:10]:\n",
    "    job_title=element.find_element(By.XPATH,'.//a[@class=\"title \"]').text\n",
    "    location_elements = element.find_elements(By.XPATH, \".//span[@class='locWdth']\")\n",
    "    location = location_elements[0].text if location_elements else None\n",
    "    experience_elements = element.find_elements(By.XPATH, \".//span[@class='expwdth']\")\n",
    "    experience = experience_elements[0].text if experience_elements else None\n",
    "    company_elements = element.find_elements(By.XPATH, \".//a[contains(@class, 'comp-name')]\")\n",
    "    company_name = company_elements[0].text if company_elements else None\n",
    "    jobs.append({\"Job Title\":job_title,\"Location\":location,\"Company_Name\":company_name,\"Experience_Required\":experience})\n",
    "df=pd.DataFrame(jobs)\n",
    "\n",
    "\n",
    "df.index=range(1,len(df)+1)#set the range of the index to avoid 0 indexing\n",
    "\n",
    "#Display the dataframe\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c85d4c5",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for ‚ÄúData Scientist‚Äù Job position in ‚ÄúBangalore‚Äù location. You have to scrape the \n",
    "job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data. \n",
    "This task will be done in following steps: \n",
    "1. First get the webpage https://www.shine.com/ \n",
    "2. Enter ‚ÄúData Analyst‚Äù in ‚ÄúJob title, Skills‚Äù field and enter ‚ÄúBangalore‚Äù in ‚Äúenter the location‚Äù field. \n",
    "3. Then click the searchbutton.  \n",
    "4. Then scrape the data for the first 10 jobs results you get.  \n",
    "5. Finally create a dataframe of the scraped data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ba0d2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience_Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore\\n+6</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore\\n+8</td>\n",
       "      <td>spento papers (india) llp</td>\n",
       "      <td>12 to 22 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore\\n+9</td>\n",
       "      <td>future solution centre</td>\n",
       "      <td>2 to 7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore\\n+2</td>\n",
       "      <td>the christopher's consulting and re...</td>\n",
       "      <td>0 to 2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>eliterecruitments hiring for global...</td>\n",
       "      <td>4 to 8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore\\n+9</td>\n",
       "      <td>divya staffing solution</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Science Analytics</td>\n",
       "      <td>Bangalore\\n+7</td>\n",
       "      <td>mackenzie modern it solutions priva...</td>\n",
       "      <td>5 to 8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Science Manager</td>\n",
       "      <td>Bangalore\\n+7</td>\n",
       "      <td>mackenzie modern it solutions priva...</td>\n",
       "      <td>3 to 8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore\\n+4</td>\n",
       "      <td>aryan technology</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Management Team Leader</td>\n",
       "      <td>Bangalore\\n+9</td>\n",
       "      <td>overnet trading private limited</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Job_title   Job_location  \\\n",
       "1                Data Scientist  Bangalore\\n+6   \n",
       "2           Lead Data Scientist  Bangalore\\n+8   \n",
       "3                Data Scientist  Bangalore\\n+9   \n",
       "4                Data Scientist  Bangalore\\n+2   \n",
       "5                Data Scientist      Bangalore   \n",
       "6                Data Scientist  Bangalore\\n+9   \n",
       "7        Data Science Analytics  Bangalore\\n+7   \n",
       "8          Data Science Manager  Bangalore\\n+7   \n",
       "9                  Data Analyst  Bangalore\\n+4   \n",
       "10  Data Management Team Leader  Bangalore\\n+9   \n",
       "\n",
       "                                   Company Experience_Required  \n",
       "1                            techno endura          0 to 2 Yrs  \n",
       "2                spento papers (india) llp        12 to 22 Yrs  \n",
       "3                   future solution centre          2 to 7 Yrs  \n",
       "4   the christopher's consulting and re...          0 to 2 Yrs  \n",
       "5   eliterecruitments hiring for global...          4 to 8 Yrs  \n",
       "6                  divya staffing solution          0 to 4 Yrs  \n",
       "7   mackenzie modern it solutions priva...          5 to 8 Yrs  \n",
       "8   mackenzie modern it solutions priva...          3 to 8 Yrs  \n",
       "9                         aryan technology          0 to 4 Yrs  \n",
       "10         overnet trading private limited          0 to 4 Yrs  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By#In Selenium, from selenium.webdriver.common.\n",
    "#by import By is used to import the By class, which is an essential component for locating elements on a web page.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "\n",
    "driver=webdriver.Chrome()\n",
    "\n",
    "# get the website\n",
    "driver.get('https://www.shine.com/')\n",
    "\n",
    "# Step 2: Locate input fields for \"Job title, Skills\" and \"Location\"\n",
    "jobs=driver.find_element(By.XPATH,'/html/body/div/header/div[3]/div/div/div[1]/div/input')\n",
    "jobs.click()\n",
    "time.sleep(3)\n",
    "\n",
    "# entering designation as required in the question\n",
    "designation=driver.find_element(By.XPATH,'//div[@class=\"position-relative\"]/input[1]')\n",
    "designation.send_keys(\"Data Scientist\")\n",
    "\n",
    "# entering location as required in the question\n",
    "location=driver.find_element(By.XPATH,'//div[@class=\"position-relative\" and @id=\"select_container_id_loc\"]/input[1]')\n",
    "location.send_keys(\"Bangalore\")\n",
    "\n",
    "#entering experience\n",
    "experience=driver.find_element(By.XPATH,'//div[@id=\"select_container_id_exp\"]/input[1]')\n",
    "experience.send_keys(\"4\")\n",
    "time.sleep(2)\n",
    "\n",
    "# click on the search button to search the required jobs\n",
    "search_button=driver.find_element(By.XPATH,'//button[@type=\"submit\"]')\n",
    "search_button.click()\n",
    "time.sleep(3)\n",
    "\n",
    "Job_title=[]\n",
    "Job_location=[]\n",
    "Company_name=[]\n",
    "Experience_required=[]\n",
    "\n",
    "# Scrapping the job_title from the site:\n",
    "title_tags=driver.find_elements(By.XPATH,'//strong[@itemprop=\"name\"]/p[1]/a[1]')\n",
    "for i in title_tags[0:10]:\n",
    "    Job_title.append(i.text)\n",
    "# Scrapping the job_location from the site:\n",
    "location_tags=driver.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard_lists__fdnsc\"]/div[1]')\n",
    "for i in location_tags[0:10]:\n",
    "    Job_location.append(i.text)\n",
    "#Scrapping the company name:\n",
    "comapany_tags=driver.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard_cName__mYnow\"]/span[1]')\n",
    "for i in comapany_tags[0:10]:\n",
    "    Company_name.append(i.text)\n",
    "#Scrapping the experience required:\n",
    "experience=driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "for i in experience[0:10]:\n",
    "    Experience_required.append(i.text)\n",
    "\n",
    "# creating the dataframe/dataset by the name of df1\n",
    "df1=pd.DataFrame({\"Job_title\":Job_title,\"Job_location\":Job_location,\"Company\":Company_name,\"Experience_Required\":Experience_required})\n",
    "\n",
    "#Setting the index from 1 to the length of the dataset\n",
    "df1.index=range(1,len(Job_location)+1)\n",
    "\n",
    "#Displaying dataframe\n",
    "df1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11f1020",
   "metadata": {},
   "source": [
    "# Q3: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: \n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb/product\n",
    "reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=F\n",
    " LIPKART \n",
    "As shown in the above page you have to scrape the tick marked attributes. These are: \n",
    "1. Rating \n",
    "2. Review summary \n",
    "3. Full review \n",
    "4. You have to scrape this data for first 100reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a261670f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Very very good</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Photos super</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good Camera</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Camera is awesome\\nBest battery backup\\nA perf...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Value for money üòç</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A perfect phone and a good battery super camer...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Very nice iPhone 11 i lake</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fantastic phone</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Excellent</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Really worth of money. i just love it. It is t...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Reviews Ratings\n",
       "1                                       Very very good       5\n",
       "2                                         Photos super       5\n",
       "3                                          Good Camera       5\n",
       "4    Camera is awesome\\nBest battery backup\\nA perf...       5\n",
       "5                                    Value for money üòç       5\n",
       "..                                                 ...     ...\n",
       "96   A perfect phone and a good battery super camer...       5\n",
       "97                          Very nice iPhone 11 i lake       5\n",
       "98                                     Fantastic phone       5\n",
       "99                                           Excellent       5\n",
       "100  Really worth of money. i just love it. It is t...       5\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "\n",
    "# setup selenium webdriver\n",
    "driver=webdriver.Chrome()\n",
    "\n",
    "# wait until page is fully loaded and input fields are present\n",
    "wait=WebDriverWait(driver,30)\n",
    "\n",
    "# get the flipkart website for review\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART')\n",
    "\n",
    "reviews=[]\n",
    "count=0\n",
    "while True:\n",
    "    \n",
    "    time.sleep(2)\n",
    "    #locate the review elment\n",
    "    review_element=wait.until(EC.presence_of_all_elements_located((By.XPATH,'.//div[@class=\"col EPCmJX Ma1fCG\"]')))\n",
    "    for element in review_element:\n",
    "        if count==100:\n",
    "            break\n",
    "        Rating=element.find_element(By.XPATH,'.//div[@class=\"XQDdHH Ga3i8K\"]').text\n",
    "        Review=element.find_element(By.XPATH,'.//div[@class=\"ZmyHeo\"]/div[1]/div[1]').text\n",
    "        reviews.append({\"Reviews\":Review,\"Ratings\":Rating})\n",
    "        count+=1\n",
    "    if count==100:\n",
    "        break\n",
    "    time.sleep(2)\n",
    "    next_button=wait.until(EC.element_to_be_clickable((By.XPATH,\"//a[@class='_9QVEpD']/span[1][text()='Next']\")))\n",
    "    next_button.click()\n",
    "# creating the dataframe/dataset by the name of df2\n",
    "df2=pd.DataFrame(reviews)\n",
    "df2.index=range(1,len(df2)+1)\n",
    "#displaying Dataframe\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "787206cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c65731e",
   "metadata": {},
   "source": [
    "# Q4: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for ‚Äúsneakers‚Äù in the search \n",
    "field. \n",
    "You have to scrape 3 attributes of each sneaker: \n",
    "1. Brand \n",
    "2. Product Description \n",
    "3. Price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f739292b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sneakers_Brand</th>\n",
       "      <th>Discription</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>‚Çπ422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Deals4you</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>‚Çπ419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Red Tape</td>\n",
       "      <td>Sneaker Casual Shoes For Men | Soft Cushion In...</td>\n",
       "      <td>‚Çπ1,349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Red Tape</td>\n",
       "      <td>Sneaker Casual Shoes For Men | Soft Cushion In...</td>\n",
       "      <td>‚Çπ1,349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Shozie</td>\n",
       "      <td>Stylish Walking Partywear Sneakers Casual Shoe...</td>\n",
       "      <td>‚Çπ449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>‚Çπ625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>BERSACHE</td>\n",
       "      <td>Bersache Sneaker, Loafers ,Casual With Extra C...</td>\n",
       "      <td>‚Çπ730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>VENDOZ</td>\n",
       "      <td>Girls Stylish Casual Sports Shoe Sneakers For ...</td>\n",
       "      <td>‚Çπ639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>asian</td>\n",
       "      <td>Moscow-01 White Loafers,Chunky Shoes Sneakers ...</td>\n",
       "      <td>‚Çπ880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>asian</td>\n",
       "      <td>Boston-01 Chunky Sneakers,Loafers,Walking Shoe...</td>\n",
       "      <td>‚Çπ809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sneakers_Brand                                        Discription   Price\n",
       "1             aadi                                   Sneakers For Men    ‚Çπ422\n",
       "2        Deals4you                                 Sneakers For Women    ‚Çπ419\n",
       "3         Red Tape  Sneaker Casual Shoes For Men | Soft Cushion In...  ‚Çπ1,349\n",
       "4         Red Tape  Sneaker Casual Shoes For Men | Soft Cushion In...  ‚Çπ1,349\n",
       "5           Shozie  Stylish Walking Partywear Sneakers Casual Shoe...    ‚Çπ449\n",
       "..             ...                                                ...     ...\n",
       "96        RapidBox                                   Sneakers For Men    ‚Çπ625\n",
       "97        BERSACHE  Bersache Sneaker, Loafers ,Casual With Extra C...    ‚Çπ730\n",
       "98          VENDOZ  Girls Stylish Casual Sports Shoe Sneakers For ...    ‚Çπ639\n",
       "99           asian  Moscow-01 White Loafers,Chunky Shoes Sneakers ...    ‚Çπ880\n",
       "100          asian  Boston-01 Chunky Sneakers,Loafers,Walking Shoe...    ‚Çπ809\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "#set up selenium webdriver\n",
    "driver=webdriver.Chrome()\n",
    "\n",
    "#step:1 open the flipkart.com\n",
    "driver.get('https://www.flipkart.com/')\n",
    "\n",
    "# wait until the page is fully loaded and the input fields are present\n",
    "wait=WebDriverWait(driver,30)# increased wait time\n",
    "\n",
    "#step2: find the search field\n",
    "search_field=wait.until(EC.presence_of_element_located((By.XPATH,'.//div[@class=\"_2SmNnR\"]/input[1]')))\n",
    "\n",
    "#Step3: Enter sneakers to the search field\n",
    "search_field.send_keys('sneakers')\n",
    "\n",
    "#Step4: locate the search button\n",
    "search_button=wait.until(EC.element_to_be_clickable((By.XPATH,'.//button[@title=\"Search for Products, Brands and More\"]')))\n",
    "search_button.click()\n",
    "\n",
    "#Step 5 for the first 100 sunglasses result\n",
    "Sneakers=[]\n",
    "\n",
    "count=0\n",
    "Number_Of_Result=100\n",
    "while True:\n",
    "   \n",
    "    Sneakers_element=wait.until(EC.presence_of_all_elements_located((By.XPATH,'.//div[@class=\"hCKiGj\"]')))\n",
    "    for elements in Sneakers_element:\n",
    "        if count==Number_Of_Result:\n",
    "            break\n",
    "        brand=elements.find_element(By.XPATH,'.//div[@class=\"syl9yP\"]').text\n",
    "        discription=elements.find_element(By.XPATH,'.//a[contains(@class,\"WKTcLC\")]').text\n",
    "        price=elements.find_element(By.XPATH,'.//div[@class=\"Nx9bqj\"]').text\n",
    "        Sneakers.append({\"Sneakers_Brand\":brand,\"Discription\":discription,\"Price\":price})\n",
    "        count+=1\n",
    "        \n",
    "       \n",
    "  \n",
    "    next_Button=wait.until(EC.element_to_be_clickable((By.XPATH,\"//a[@class='_9QVEpD']/span[1][text()='Next']\")))\n",
    "    next_Button.click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    if count==Number_Of_Result:\n",
    "        break\n",
    "# Step 6: Create a DataFrame of the scraped data   \n",
    "df3=pd.DataFrame(Sneakers)\n",
    "\n",
    "# setting index from 1 to range\n",
    "df3.index=range(1,len(Sneakers)+1)\n",
    "df3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02513a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f681138",
   "metadata": {},
   "source": [
    "# Q5: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes: \n",
    "1. Brand  \n",
    "2. ProductDescription  \n",
    "3. Price  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c3cdbcaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sun_Glasses_Brand</th>\n",
       "      <th>Discription</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Being Better</td>\n",
       "      <td>Gradient, UV Protection, Riding Glasses Retro ...</td>\n",
       "      <td>‚Çπ239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OCHILA</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>‚Çπ279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (58)</td>\n",
       "      <td>‚Çπ1,099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Wayfarer ...</td>\n",
       "      <td>‚Çπ599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>‚Çπ549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>IRUS</td>\n",
       "      <td>Gradient Rectangular Sunglasses (65)</td>\n",
       "      <td>‚Çπ1,502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>HIPE</td>\n",
       "      <td>UV Protection, Night Vision Spectacle Sunglass...</td>\n",
       "      <td>‚Çπ542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Eyewearlabs</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (47)</td>\n",
       "      <td>‚Çπ1,799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>I REBEL</td>\n",
       "      <td>Night Vision, Riding Glasses, Polarized, UV Pr...</td>\n",
       "      <td>‚Çπ184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart UV Protection Wayfarer Sunglasses ...</td>\n",
       "      <td>‚Çπ529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sun_Glasses_Brand                                        Discription  \\\n",
       "1        Being Better  Gradient, UV Protection, Riding Glasses Retro ...   \n",
       "2              OCHILA              UV Protection Aviator Sunglasses (58)   \n",
       "3            Fastrack             UV Protection Wayfarer Sunglasses (58)   \n",
       "4       VINCENT CHASE  by Lenskart Polarized, UV Protection Wayfarer ...   \n",
       "5            Fastrack  Gradient, UV Protection Wayfarer Sunglasses (F...   \n",
       "..                ...                                                ...   \n",
       "96               IRUS               Gradient Rectangular Sunglasses (65)   \n",
       "97               HIPE  UV Protection, Night Vision Spectacle Sunglass...   \n",
       "98        Eyewearlabs     Polarized, UV Protection Round Sunglasses (47)   \n",
       "99            I REBEL  Night Vision, Riding Glasses, Polarized, UV Pr...   \n",
       "100     VINCENT CHASE  by Lenskart UV Protection Wayfarer Sunglasses ...   \n",
       "\n",
       "      Price  \n",
       "1      ‚Çπ239  \n",
       "2      ‚Çπ279  \n",
       "3    ‚Çπ1,099  \n",
       "4      ‚Çπ599  \n",
       "5      ‚Çπ549  \n",
       "..      ...  \n",
       "96   ‚Çπ1,502  \n",
       "97     ‚Çπ542  \n",
       "98   ‚Çπ1,799  \n",
       "99     ‚Çπ184  \n",
       "100    ‚Çπ529  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "#set up selenium webdriver\n",
    "driver=webdriver.Chrome()\n",
    "\n",
    "#step:1 open the flipkart.com\n",
    "driver.get('https://www.flipkart.com/')\n",
    "\n",
    "# wait until the page is fully loaded and the input fields are present\n",
    "wait=WebDriverWait(driver,30)# increased wait time\n",
    "\n",
    "#step2: find the search field\n",
    "search_field=wait.until(EC.presence_of_element_located((By.XPATH,'.//div[@class=\"_2SmNnR\"]/input[1]')))\n",
    "\n",
    "#Step3: Enter sunglasses to the search field\n",
    "search_field.send_keys('Sunglasses')\n",
    "\n",
    "#Step4: locate the search button\n",
    "search_button=wait.until(EC.element_to_be_clickable((By.XPATH,'.//button[@title=\"Search for Products, Brands and More\"]')))\n",
    "search_button.click()\n",
    "\n",
    "#Step 5 for the first 100 sunglasses result\n",
    "Sun_glasses=[]\n",
    "\n",
    "count=0\n",
    "Number_Of_Result=100\n",
    "while True:\n",
    "   #\n",
    "    Sun_glasses_element=wait.until(EC.presence_of_all_elements_located((By.XPATH,'.//div[@class=\"hCKiGj\"]')))\n",
    "    for elements in Sun_glasses_element:\n",
    "        if count==Number_Of_Result:\n",
    "            break\n",
    "        brand=elements.find_element(By.XPATH,'.//div[@class=\"syl9yP\"]').text\n",
    "        discription=elements.find_element(By.XPATH,'.//a[contains(@class,\"WKTcLC\")]').text\n",
    "        price=elements.find_element(By.XPATH,'.//div[@class=\"Nx9bqj\"]').text\n",
    "        Sun_glasses.append({\"Sun_Glasses_Brand\":brand,\"Discription\":discription,\"Price\":price})\n",
    "        count+=1\n",
    "        \n",
    "       \n",
    "  \n",
    "    next_Button=wait.until(EC.element_to_be_clickable((By.XPATH,\"//a[@class='_9QVEpD']/span[1][text()='Next']\")))\n",
    "    next_Button.click()\n",
    "    time.sleep(5)\n",
    "\n",
    "    if count==Number_Of_Result:\n",
    "        break\n",
    "# Step 6: Create a DataFrame of the scraped data   \n",
    "df4=pd.DataFrame(Sun_glasses)\n",
    "\n",
    "# setting index from 1 to range\n",
    "df4.index=range(1,len(Sun_glasses)+1)\n",
    "df4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0aa86bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f583403",
   "metadata": {},
   "source": [
    "# Q6: Go to webpage https://www.amazon.in/ Enter ‚ÄúLaptop‚Äù in the search field and then click the search icon. Then set CPU \n",
    "Type filter to ‚ÄúIntel Core i7‚Äù as shown in the below image: \n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop: \n",
    "1. Title \n",
    "2. Ratings \n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee92ed0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acer Aspire Lite 12th Gen Intel Core i7-1255U ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS Vivobook 15, 15.6\" (39.62cm) FHD, Intel C...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP Laptop 15s, 12th Gen Intel Core i7-1255U, 1...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acer Travelmate Business Laptop Intel Core i7-...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dell Inspiron 3530 Laptop, 13th Generation Int...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Refurbished) Dell Latitude 7480 14in FHD Lapt...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dell [Smartchoice] Inspiron 5430 Thin &amp; Light ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MSI Thin 15, Intel 13th Gen. Core i7-13620H, 4...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Acer Nitro V Gaming Laptop 13th Gen Intel Core...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title Rating Price\n",
       "1   Acer Aspire Lite 12th Gen Intel Core i7-1255U ...             \n",
       "2   ASUS Vivobook 15, 15.6\" (39.62cm) FHD, Intel C...             \n",
       "3   HP Laptop 15s, 12th Gen Intel Core i7-1255U, 1...             \n",
       "4   Acer Travelmate Business Laptop Intel Core i7-...             \n",
       "5   HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...             \n",
       "6   Dell Inspiron 3530 Laptop, 13th Generation Int...             \n",
       "7   (Refurbished) Dell Latitude 7480 14in FHD Lapt...             \n",
       "8   Dell [Smartchoice] Inspiron 5430 Thin & Light ...             \n",
       "9   MSI Thin 15, Intel 13th Gen. Core i7-13620H, 4...             \n",
       "10  Acer Nitro V Gaming Laptop 13th Gen Intel Core...             "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "#set up selenium webdriver\n",
    "driver=webdriver.Chrome()\n",
    "\n",
    "#step:1 open the Amazon.com\n",
    "driver.get('https://www.amazon.in/')\n",
    "\n",
    "# wait until the page is fully loaded and the input fields are present\n",
    "wait=WebDriverWait(driver,30)# increased wait time\n",
    "\n",
    "#step2: find the search field\n",
    "search_field=wait.until(EC.presence_of_element_located((By.XPATH,'.//input[@placeholder=\"Search Amazon.in\"]')))\n",
    "\n",
    "#Step3: Enter Laptop to the search field\n",
    "search_field.send_keys('Laptop')\n",
    "\n",
    "#Step4: locate the search button\n",
    "search_button=wait.until(EC.element_to_be_clickable((By.XPATH,'.//input[@id=\"nav-search-submit-button\"]')))\n",
    "search_button.click()\n",
    "\n",
    "# select the filter with intel Corei7\n",
    "intel_Core_i7=wait.until(EC.element_to_be_clickable((By.XPATH,'.//li[@aria-label=\"Intel Core i7\"]/span[1]/a[1]/div[1]')))\n",
    "intel_Core_i7.click()\n",
    "\n",
    "\n",
    "#Step 5 for the first 10 Laptops result\n",
    "Laptop=[]\n",
    "\n",
    "count=0\n",
    "Number_Of_Result=10\n",
    "while True:\n",
    "    laptop_element=wait.until(EC.presence_of_all_elements_located((By.XPATH,'.//div[@class=\"a-section a-spacing-small a-spacing-top-small\"]')))[1:]\n",
    "    time.sleep(4)\n",
    "    for elements in laptop_element:\n",
    "        if count==Number_Of_Result:\n",
    "            break\n",
    "        Title=elements.find_element(By.XPATH,'.//span[@class=\"a-size-medium a-color-base a-text-normal\"]').text\n",
    "        Rating=elements.find_element(By.XPATH,'.//i[@data-cy=\"reviews-ratings-slot\"]/span[1]').text\n",
    "        #rating_element =wait.until(EC.visibility_of_element_located((By.XPATH, './/i[@data-cy=\"reviews-ratings-slot\"]/span[1]')))\n",
    "    \n",
    "        price=elements.find_element(By.XPATH,'.//span[@class=\"a-price\"]/span[1]').text\n",
    "        Laptop.append({\"Title\":Title,\"Rating\":Rating,\"Price\":price})\n",
    "        count+=1\n",
    "        \n",
    "       \n",
    "  \n",
    "    next_Button=wait.until(EC.element_to_be_clickable((By.XPATH,\".//a[contains(@aria-label,'next page')]\")))\n",
    "    next_Button.click()\n",
    "    time.sleep(5)\n",
    "\n",
    "    if count==Number_Of_Result:\n",
    "        break\n",
    "# Step 6: Create a DataFrame of the scraped data   \n",
    "df5=pd.DataFrame(Laptop)\n",
    "\n",
    "# setting index from 1 to range\n",
    "df5.index=range(1,len(Laptop)+1)\n",
    "df5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7126f529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60afca61",
   "metadata": {},
   "source": [
    "# Q6: Write a python program to scrape data for Top 1000 Quotes of All Time. \n",
    "The above task will be done in following steps: \n",
    "1. First get the webpagehttps://www.azquotes.com/ \n",
    "2. Click on Top Quote \n",
    "3. Than scrap a) Quote b) Author c) Type Of Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "298aedbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Set up Selenium WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "try:\n",
    "    # Open the website\n",
    "    driver.get('https://www.azquotes.com/')\n",
    "\n",
    "    # Wait until the page is fully loaded and the input fields are present\n",
    "    wait = WebDriverWait(driver, 30)\n",
    "\n",
    "    # Locate and click the Top Quotes link\n",
    "    top_quotes = wait.until(EC.element_to_be_clickable((By.XPATH, './/a[@href=\"/top_quotes.html\"]')))\n",
    "    top_quotes.click()\n",
    "\n",
    "    quotes = []\n",
    "    Desired_number = 1000\n",
    "    count = 0\n",
    "\n",
    "    while count < Desired_number:\n",
    "        try:\n",
    "            # Wait for the quotes to be present\n",
    "            quote_elements = wait.until(EC.presence_of_all_elements_located((By.XPATH, './/div[@class=\"wrap-block\"]')))\n",
    "\n",
    "            for element in quote_elements:\n",
    "                if count >= Desired_number:\n",
    "                    break\n",
    "                \n",
    "                try:\n",
    "                    quote = element.find_element(By.XPATH, './/a[@class=\"title\"]').text\n",
    "                    author = element.find_element(By.XPATH, './/div[@class=\"author\"]/a[1]').text\n",
    "                    tags = element.find_elements(By.XPATH, './/div[@class=\"tags\"]/a')\n",
    "\n",
    "                    # Extract up to three tags, defaulting to empty strings if fewer are present\n",
    "                    tag1 = tags[0].text if len(tags) > 0 else \"\"\n",
    "                    tag2 = tags[1].text if len(tags) > 1 else \"\"\n",
    "                    tag3 = tags[2].text if len(tags) > 2 else \"\"\n",
    "\n",
    "                    quotes.append({\"Quote\": quote, \"Author\": author, \"Type_of_Quotes\": [tag1, tag2, tag3]})\n",
    "                    count += 1\n",
    "\n",
    "                    if count >= Desired_number:\n",
    "                        break\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing an element: {e}\")\n",
    "                    continue\n",
    "\n",
    "            # Click the \"Next\" button if not finished\n",
    "            if count < Desired_number:\n",
    "                try:\n",
    "                    next_button = wait.until(EC.element_to_be_clickable((By.XPATH, './/li[@class=\"next\"]')))\n",
    "                    next_button.click()\n",
    "                    time.sleep(2)  # Slight delay to allow page to load\n",
    "                except Exception as e:\n",
    "                    print(f\"Error finding or clicking the next button: {e}\")\n",
    "                    break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching quotes: {e}\")\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    # Close the WebDriver\n",
    "    driver.quit()\n",
    "\n",
    "# Convert the quotes list to a DataFrame for easier handling\n",
    "df = pd.DataFrame(quotes)\n",
    "\n",
    "def process_tuple(x):\n",
    "    a, b,c = x  # Unpack the tuple\n",
    "    # Perform some operations\n",
    "    return f'{a}, {b}, {c}'\n",
    "\n",
    "# Apply the function to each element in the column\n",
    "df['Type_of_Quotes'] = df['Type_of_Quotes'].apply(process_tuple)\n",
    "\n",
    "df.index=range(1,len(df)+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "52c5e64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Author</th>\n",
       "      <th>Type_of_Quotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Essence, Deep Thought, Transcendentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspiration, Past, Trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country, Peace, War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Inspirational, Motivational, Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>4th Of July, Food, Patriotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Regret for the things we did can be tempered b...</td>\n",
       "      <td>Sydney J. Harris</td>\n",
       "      <td>Love, Inspirational, Motivational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>America... just a nation of two hundred millio...</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Gun, Two, Qualms About</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>For every disciplined effort there is a multip...</td>\n",
       "      <td>Jim Rohn</td>\n",
       "      <td>Inspirational, Greatness, Best Effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>The spiritual journey is individual, highly pe...</td>\n",
       "      <td>Ram Dass</td>\n",
       "      <td>Spiritual, Truth, Yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>The mind is not a vessel to be filled but a fi...</td>\n",
       "      <td>Plutarch</td>\n",
       "      <td>Inspirational, Leadership, Education</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Quote              Author  \\\n",
       "1     The essence of strategy is choosing what not t...      Michael Porter   \n",
       "2     One cannot and must not try to erase the past ...          Golda Meir   \n",
       "3     Patriotism means to stand by the country. It d...  Theodore Roosevelt   \n",
       "4     Death is something inevitable. When a man has ...      Nelson Mandela   \n",
       "5     You have to love a nation that celebrates its ...        Erma Bombeck   \n",
       "...                                                 ...                 ...   \n",
       "996   Regret for the things we did can be tempered b...    Sydney J. Harris   \n",
       "997   America... just a nation of two hundred millio...  Hunter S. Thompson   \n",
       "998   For every disciplined effort there is a multip...            Jim Rohn   \n",
       "999   The spiritual journey is individual, highly pe...            Ram Dass   \n",
       "1000  The mind is not a vessel to be filled but a fi...            Plutarch   \n",
       "\n",
       "                                Type_of_Quotes  \n",
       "1     Essence, Deep Thought, Transcendentalism  \n",
       "2                    Inspiration, Past, Trying  \n",
       "3                          Country, Peace, War  \n",
       "4           Inspirational, Motivational, Death  \n",
       "5                 4th Of July, Food, Patriotic  \n",
       "...                                        ...  \n",
       "996          Love, Inspirational, Motivational  \n",
       "997                     Gun, Two, Qualms About  \n",
       "998      Inspirational, Greatness, Best Effort  \n",
       "999                     Spiritual, Truth, Yoga  \n",
       "1000      Inspirational, Leadership, Education  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3169c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
